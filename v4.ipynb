{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in c:\\users\\samsung\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (23.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seaborn is already installed.\n"
          ]
        }
      ],
      "source": [
        "#check if seaborn is installed\n",
        "\n",
        "import subprocess\n",
        "\n",
        "try:\n",
        "    subprocess.check_call(['pip', 'show', 'seaborn'])\n",
        "except subprocess.CalledProcessError:\n",
        "    # Seaborn is not installed\n",
        "    %pip install seaborn\n",
        "else:\n",
        "    print('Seaborn is already installed.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "#check if plotly is installed\n",
        "\n",
        "import subprocess\n",
        "\n",
        "try:\n",
        "    subprocess.check_call(['pip', 'show', 'plotly'])\n",
        "except subprocess.CalledProcessError:\n",
        "    # plotly is not installed\n",
        "    %pip install plotly\n",
        "else:\n",
        "    print('plotly is already installed.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#check if xgboost is installed\n",
        "\n",
        "import subprocess\n",
        "\n",
        "try:\n",
        "    subprocess.check_call(['pip', 'show', 'xgboost'])\n",
        "except subprocess.CalledProcessError:\n",
        "    # xgboost is not installed\n",
        "    %pip install xgboost\n",
        "else:\n",
        "    print('xgboost is already installed.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKbBMUSd-rgl"
      },
      "outputs": [],
      "source": [
        "# import necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from sklearn import preprocessing\n",
        "import matplotlib \n",
        "matplotlib.style.use('ggplot')\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# Set display options to show all rows and columns\n",
        "# pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUvDowUwCL-j",
        "outputId": "72070054-98d2-443f-c57e-46a9ff2380d6"
      },
      "outputs": [],
      "source": [
        "# importing openpyxl module\n",
        "import openpyxl\n",
        "\n",
        "# input excel file path\n",
        "inputExcelFile =\"MorpaData.xlsx\"\n",
        "\n",
        "# creating or loading an excel workbook\n",
        "newWorkbook = openpyxl.load_workbook(inputExcelFile)\n",
        "\n",
        "# printing all the sheetnames in an excel file using sheetnames attribute\n",
        "print('The Sheet names of the given excel file: ')\n",
        "\n",
        "# Getting the sheetnames as a list using the sheetnames attribute\n",
        "sheetNames=newWorkbook.sheetnames\n",
        "\n",
        "# Traversing in the sheetNames list\n",
        "for name in sheetNames:\n",
        "   print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKZsCLZ5DtkY",
        "outputId": "a0717b59-17a0-4e8f-cdcb-5e8f796cbfca"
      },
      "outputs": [],
      "source": [
        "# get the member data from excel\n",
        "\n",
        "member_df = pd.read_excel('MorpaData.xlsx',sheet_name='Üye Listesi')\n",
        "print(member_df.head(10),'\\n\\n')\n",
        "\n",
        "print(member_df.info())\n",
        "\n",
        "# get the unique number of members\n",
        "\n",
        "print(member_df['Üye'].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "er0hlnd5DwP4",
        "outputId": "63b4ff6e-1344-4d60-8b5d-ee5b7eb18837"
      },
      "outputs": [],
      "source": [
        "# get the Login logs data from excel\n",
        "\n",
        "login_df = pd.read_excel('MorpaData.xlsx',sheet_name='Giriş Logları')\n",
        "login_df['Giriş Zamanı'] = pd.to_datetime(login_df['Giriş Zamanı'], format='%d/%m/%Y %H:%M:%S')\n",
        "login_df['Çıkış Zamanı'] = pd.to_datetime(login_df['Çıkış Zamanı'], format='%d/%m/%Y %H:%M:%S')\n",
        "print(login_df.head(10),'\\n\\n')\n",
        "\n",
        "print(login_df.info(),'\\n\\n')\n",
        "\n",
        "\n",
        "# get the unique number of members on login data\n",
        "print(\"unique member count on login data: \",login_df['Üye'].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lf3miMv5D6md",
        "outputId": "31746262-361e-44b5-fa40-7e2994d56103"
      },
      "outputs": [],
      "source": [
        "# get the lecturing logs data from excel\n",
        "\n",
        "lecturing_df = pd.read_excel('MorpaData.xlsx',sheet_name='Konu anlatımı')\n",
        "lecturing_df['Giriş Zamanı'] = pd.to_datetime(lecturing_df['Giriş Zamanı'], format='%d/%m/%Y %H:%M:%S')\n",
        "lecturing_df['Çıkış Zamanı'] = pd.to_datetime(lecturing_df['Çıkış Zamanı'], format='%d/%m/%Y %H:%M:%S')\n",
        "\n",
        "# calculate the duration of the lecturing\n",
        "\n",
        "lecturing_df['lec_Süre'] = (lecturing_df['Çıkış Zamanı'] - lecturing_df['Giriş Zamanı']).dt.total_seconds().astype(int)\n",
        "\n",
        "print(lecturing_df.head(10),'\\n\\n')\n",
        "\n",
        "print(lecturing_df.info(),'\\n\\n')\n",
        "\n",
        "\n",
        "# get the unique number of members on lecturing data\n",
        "print(\"Unique number of users on lecturing: \", lecturing_df['Üye'].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO-RVuCTD-nn",
        "outputId": "a38cf49d-61ed-417e-93e5-d3eb44dfcbaa"
      },
      "outputs": [],
      "source": [
        "# get the member studies data from excel\n",
        "\n",
        "studies_df = pd.read_excel('MorpaData.xlsx',sheet_name='çalışmalar')\n",
        "studies_df['Giriş Zamanı'] = pd.to_datetime(studies_df['Giriş Zamanı'], format='%d/%m/%Y %H:%M:%S')\n",
        "studies_df['Çıkış Zamanı'] = pd.to_datetime(studies_df['Çıkış Zamanı'], format='%d/%m/%Y %H:%M:%S')\n",
        "\n",
        "studies_df['stud_Süre'] = (studies_df['Çıkış Zamanı'] - studies_df['Giriş Zamanı']).dt.total_seconds().astype(int)\n",
        "\n",
        "print(studies_df.head(10),'\\n\\n')\n",
        "\n",
        "print(studies_df.info(),'\\n\\n')\n",
        "\n",
        "# get the unique number of members on studies data\n",
        "print(\"unique member count on studies data: \",studies_df['Üye'].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QGYXqBHEIDR",
        "outputId": "eba89494-d351-4c8d-a0d5-d0967583d3c0"
      },
      "outputs": [],
      "source": [
        "# get the member exams data from excel\n",
        "\n",
        "exams_df = pd.read_excel('MorpaData.xlsx',sheet_name='Sınav')\n",
        "exams_df['Giriş Zamanı'] = exams_df['Giriş Zamanı'].apply(lambda x: x.strftime(\"%d/%m/%Y  %H:%M:%S\"))\n",
        "exams_df['Çıkış Zamanı'] = exams_df['Çıkış Zamanı'].apply(lambda x: x.strftime(\"%d/%m/%Y  %H:%M:%S\"))\n",
        "\n",
        "exams_df['Giriş Zamanı'] = pd.to_datetime(exams_df['Giriş Zamanı'], format='%d/%m/%Y %H:%M:%S')\n",
        "exams_df['Çıkış Zamanı'] = pd.to_datetime(exams_df['Çıkış Zamanı'], format='%d/%m/%Y %H:%M:%S')\n",
        "\n",
        "exams_df['Giriş Zamanı']\n",
        "\n",
        "print(exams_df.head(10),'\\n\\n')\n",
        "\n",
        "print(exams_df.info(),'\\n\\n')\n",
        "\n",
        "# get the unique number of members on exams data\n",
        "print(\"unique member count on exams data: \",exams_df['Üye'].nunique())\n",
        "\n",
        "\n",
        "# wrong answers are not deducted from the total score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "uqgM7MckE2T4",
        "outputId": "0b8a4f24-5e55-4d29-beba-dd70ca49b2a3"
      },
      "outputs": [],
      "source": [
        "# get the member subject data from excel\n",
        "\n",
        "subject_df = pd.read_excel('MorpaData.xlsx',sheet_name='konu')\n",
        "subject_df.head(10)\n",
        "\n",
        "#sort according to aktif materyal sayısı\n",
        "\n",
        "subject_df.sort_values(by=['Aktif Materyal Sayısı'],ascending=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "iw9InXsHF6i8",
        "outputId": "4a233ab5-6ce8-486c-f5a6-b4b2fa956489"
      },
      "outputs": [],
      "source": [
        "#left join the exam and subject dataframes\n",
        "\n",
        "exam_subject_df = pd.merge(exams_df,subject_df,how='left',left_on='Konu',right_on='Konu')\n",
        "\n",
        "# change column names for further join operations\n",
        "exam_subject_df.rename(\n",
        "    columns={\"Giriş Zamanı\": \"S_Giriş Zamanı\", \"Çıkış Zamanı\": \"S_Çıkış Zamanı\", \"Süre\":\"S_süre\"},\n",
        "    inplace=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# drop non-numeric sınıf rows\n",
        "\n",
        "exam_subject_df = exam_subject_df[exam_subject_df['Sınıf'].notna()]\n",
        "\n",
        "exam_subject_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "exam_subject_df['Sınıf'] = exam_subject_df['Sınıf'].astype('int64')\n",
        "exam_subject_df['Ders'] = exam_subject_df['Ders'].astype('int64')\n",
        "exam_subject_df['Aktif Materyal Sayısı'] = exam_subject_df['Aktif Materyal Sayısı'].astype('int64')\n",
        "exam_subject_df['Toplam Materyal Sayısı'] = exam_subject_df['Toplam Materyal Sayısı'].astype('int64')\n",
        "\n",
        "exam_subject_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-yZKkBTdRVb"
      },
      "outputs": [],
      "source": [
        "# add cumulative lecture time to exam_subject dataframe for each member according to the subject prior to exam date s_Giriş Zamanı\n",
        "\n",
        "# calculate cumulative lecture time before the exam date for each member of each subject\n",
        "exam_subject_df['cum_lecture_time'] = 0\n",
        "for index, row in exam_subject_df.iterrows():\n",
        "    df = lecturing_df[lecturing_df['Üye'] == row['Üye']]\n",
        "    df = df[df['Konu'] == row['Konu']]\n",
        "    df = df[df['Giriş Zamanı'] < row['S_Giriş Zamanı']]\n",
        "    df['lec_Süre'] = df['lec_Süre'].astype('int64')\n",
        "    exam_subject_df.at[index,'cum_lecture_time'] = df['lec_Süre'].sum()\n",
        "\n",
        "# calculate cumulative study time before the exam date for each member of each subject\n",
        "exam_subject_df['cum_study_time'] = 0\n",
        "for index, row in exam_subject_df.iterrows():\n",
        "    df = studies_df[studies_df['Üye'] == row['Üye']]\n",
        "    df = df[df['Konu'] == row['Konu']]\n",
        "    df = df[df['Giriş Zamanı'] < row['S_Giriş Zamanı']]\n",
        "    df['stud_Süre'] = df['stud_Süre'].astype('int64')\n",
        "    exam_subject_df.at[index,'cum_study_time'] = df['stud_Süre'].sum()\n",
        "\n",
        "exam_subject_df['total_study_time'] = exam_subject_df['cum_lecture_time'] + exam_subject_df['cum_study_time']\n",
        "        \n",
        "exam_subject_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TJnVX2PMr3z",
        "outputId": "6cf92ae3-861c-44d0-87e5-149fb6566244"
      },
      "outputs": [],
      "source": [
        "# to tag the members who attempt gaming the system, I crate a deep copy of exams_df to exams_df_gtsLabeled.\n",
        "\n",
        "exams_df_gtsLabeled = exam_subject_df.copy(deep=True)\n",
        "\n",
        "# create a new column for labeling and overlapping time\n",
        "\n",
        "exams_df_gtsLabeled['Label'] = \"\"\n",
        "exams_df_gtsLabeled['Overlap (secs.)'] = \"\"\n",
        "\n",
        "# update the index of exams_df_gtsLabeled\n",
        "\n",
        "exams_df_gtsLabeled.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# then we write the conditions for labeling the data who \"Gaming the System\". 1 for gaming, 0 for not gaming.\n",
        "\n",
        "for i in range(1,len(exams_df_gtsLabeled)):\n",
        "    if exams_df_gtsLabeled['Üye'][i-1] == exams_df_gtsLabeled['Üye'][i]:\n",
        "        if exams_df_gtsLabeled['Sınav'][i-1] == exams_df_gtsLabeled['Sınav'][i]:\n",
        "            if exams_df_gtsLabeled['Konu'][i-1] == exams_df_gtsLabeled['Konu'][i]:\n",
        "                if (exams_df_gtsLabeled['S_Çıkış Zamanı'][i-1] > exams_df_gtsLabeled['S_Giriş Zamanı'][i]) and (exams_df_gtsLabeled['Puan'][i-1] < exams_df_gtsLabeled['Puan'][i]) and (exams_df_gtsLabeled['GirişLog'][i-1] == exams_df_gtsLabeled['GirişLog'][i]):\n",
        "                    exams_df_gtsLabeled['Label'][i] = 1\n",
        "                    exams_df_gtsLabeled['Overlap (secs.)'][i] = (exams_df_gtsLabeled['S_Giriş Zamanı'][i] - exams_df_gtsLabeled['S_Çıkış Zamanı'][i-1]).total_seconds() * -1  # this is the overlapping time in seconds \n",
        "\n",
        "exams_df_gtsLabeled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Ce-tzZEyQ2g4",
        "outputId": "bc3e0546-414c-471d-96e7-2d000c3be6cb"
      },
      "outputs": [],
      "source": [
        "#Sort the tagged data according to the member and subject\n",
        "\n",
        "exams_df_gtsLabeled.sort_values(by=['Konu','Üye'])\n",
        "\n",
        "# name the table as df for the sake of simplicity\n",
        "\n",
        "df = exams_df_gtsLabeled\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Label'].value_counts()\n",
        "\n",
        "# we have 7878 rows data and 290 of them are labeled as 1. This means that 290 members attempted gaming the system.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the gaming the system data\n",
        "\n",
        "df.loc[df['Label'] == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fill with zero if Label column is not 1\n",
        "\n",
        "df.replace(\"\", 0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check the label value counts\n",
        "\n",
        "df['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWgyZphpREp4"
      },
      "source": [
        "# ML SIDE"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#describe the latest df \n",
        "\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#change object type to related datatype. Label and Overlap(secs.) are going to be int64\n",
        "\n",
        "df['Overlap (secs.)'] = df['Overlap (secs.)'].astype('int64')\n",
        "\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# change the datetime type to unix time\n",
        "\n",
        "df['S_Giriş Zamanı'] = df['S_Giriş Zamanı'].astype('int64') // 10**9\n",
        "df['S_Çıkış Zamanı'] = df['S_Çıkış Zamanı'].astype('int64') // 10**9\n",
        "\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.options.display.float_format = '{:.0f}'.format\n",
        "\n",
        "df.describe().T  # T is for transpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Shows the Distribution of GTS with respect to Class\n",
        "\n",
        "# Subset your data to only include Label=1\n",
        "df_label_1 = df[df[\"Label\"] == 1]\n",
        "\n",
        "sns.countplot(x=\"Sınıf\", hue=\"Label\", data=df_label_1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute the correlation matrix\n",
        "corr = df.corr()\n",
        "\n",
        "# Generate a heatmap plot of the correlation matrix using Seaborn\n",
        "sns.heatmap(corr, cmap=\"YlGnBu\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# we need to drop the columns that are highly correlated with each other to avoid multicollinearity\n",
        "\n",
        "df.drop([\"Doğru Sayısı\",\"Yanlış Sayısı\",\"Boş Sayısı\",\"cum_lecture_time\",\"cum_study_time\",\"Overlap (secs.)\"], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute the correlation matrix\n",
        "corr = df.corr()\n",
        "\n",
        "# Generate a heatmap plot of the correlation matrix using Seaborn\n",
        "sns.heatmap(corr, cmap=\"YlGnBu\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to remove the columns which has single value, we investigate the unique values of each column\n",
        "\n",
        "print(df['Sınav Türü'].unique())\n",
        "print(df['Sınıf'].unique())\n",
        "print(df['Label'].unique())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "we have different values on the columns so no need any extraction for unique values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have no null values so no need to deal with missing data. Since we are planning to use xgboost, we need only int, float and bool values. Our data is already in this format so no need to convert any data type. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train.value_counts()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Format the data 1 - Split data into train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# since we try to predict the Label column, we need to drop this column before assigning the data to X\n",
        "\n",
        "X = df.drop('Label', axis=1).copy()\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# y is the Label column which we want to predict\n",
        "\n",
        "y = df['Label'].copy()\n",
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Format the data 2 : One Hot Encoding \n",
        "\n",
        "# One Hot Encoding is not good for logistic regression but great for tree based models for categorical variables\n",
        "\n",
        "X_encoded = pd.get_dummies(X, columns=['Üye', 'Sınav','Konu','Sınav Türü','GirişLog','Sınıf','Ders','Aktif Materyal Sayısı', 'Toplam Materyal Sayısı'])\n",
        "\n",
        "print(X_encoded.info())\n",
        "\n",
        "X_encoded.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# verify that y has only 0 and 1 values\n",
        "\n",
        "y.unique()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build a preliminary XGBoost Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check the target data imbalance\n",
        "\n",
        "sum(y)/len(y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our target variable is highly imbalanced. Thus, we use stratified sampling to split the data into train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# split the data into train and test sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, random_state=42, test_size=0.2, stratify=y)   #test_size=0.2 could be added to split in %80 train and %20 test "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check if stratification is done correctly\n",
        "\n",
        "print('y_train ratio:', sum(y_train)/len(y_train))\n",
        "print('y_test ratio:',sum(y_test)/len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(y_test)/(len(y_test)+len(y_train))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It seems stratified sampling is working well. \n",
        "\n",
        "\n",
        "Now we use XGB Classifier and Instead of determinin the optimal number of trees, we use early stopping to determine the optimal number of trees. Early Stopping is a method that allows you to specify a performance metric to evaluate your model on every step of the training process, and stop the training process when the performance metric no longer improves for a given number of steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create XGBClassifier model\n",
        "\n",
        "clf_xgb = xgb.XGBClassifier(objective='binary:logistic', seed=42)\n",
        "clf_xgb.fit(X_train, y_train, verbose=True, early_stopping_rounds=10, eval_metric='aucpr', eval_set=[(X_test, y_test)]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay.from_estimator(clf_xgb, X_test, y_test, cmap='Blues', values_format='d' ,display_labels=['Not GTS', 'GTS'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our default XGBoost model is not performing well. We need to tune the hyperparameters to improve the performance.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimize the hyperparameters using cross validation and GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # first try\n",
        "\n",
        "# param_grid = {\n",
        "#     'max_depth': [3, 6, 9],\n",
        "#     'learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1],\n",
        "#     #'n_estimators': [100, 200],\n",
        "#     #'gamma': [0.0, 0.25, 0.5, 1.0],\n",
        "#     #'subsample': [0.5, 0.9],\n",
        "#     #'colsample_bytree': [0.3, 0.5, 0.9],\n",
        "#     #'reg_alpha': [0, 0.25, 0.5, 0.75, 1],\n",
        "#     #'reg_lambda': [10, 20, 100],\n",
        "#     'scale_pos_weight': [1, 3, 5]\n",
        "# }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# since the operation takes too long, we commented out the code\n",
        "\n",
        "\n",
        "# optimal_params = GridSearchCV(\n",
        "#     estimator=clf_xgb,\n",
        "#     param_grid=param_grid,\n",
        "#     scoring='roc_auc',\n",
        "#     verbose=4,\n",
        "#     cv=5\n",
        "# )\n",
        "\n",
        "\n",
        "# optimal_params.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# optimal_params.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# optimal_params.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# optimal_params.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# resultsdf = pd.DataFrame(optimal_params.cv_results_)\n",
        "# resultsdf = resultsdf.sort_values(by=['rank_test_score'], ascending=False)\n",
        "# resultsdf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# we use xgboost model with optimized parameters.\n",
        "\n",
        "clf_xgb = xgb.XGBClassifier(seed=42,\n",
        "                            objective='binary:logistic',\n",
        "                            gamma=0.25,\n",
        "                            learning_rate=0.01,\n",
        "                            max_depth=6,                            \n",
        "                            reg_alpha=0.25,\n",
        "                            reg_lambda=5,\n",
        "                            scale_pos_weight=30,\n",
        "                            subsample=0.9,\n",
        "                            colsample_bytree=0.5,\n",
        "                            n_estimators=100,\n",
        "                            )\n",
        "\n",
        "clf_xgb.fit(X_train, \n",
        "            y_train, \n",
        "            verbose=True, \n",
        "            early_stopping_rounds=10, \n",
        "            eval_metric='aucpr', \n",
        "            eval_set=[(X_test, y_test)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay.from_estimator(clf_xgb, X_test, y_test, cmap='Blues', values_format='d' ,display_labels=['Not GTS', 'GTS'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# buraya tree çizdir.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "3e4e368f4678aeea63aa88b109cf85079962017e54a5bcf2a7b2b7c89b67607e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
