{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in c:\\users\\melih\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (23.1)\n",
            "Collecting pip\n",
            "  Downloading pip-23.1.1-py3-none-any.whl (2.1 MB)\n",
            "                                              0.0/2.1 MB ? eta -:--:--\n",
            "                                              0.0/2.1 MB 1.4 MB/s eta 0:00:02\n",
            "     --                                       0.1/2.1 MB 1.3 MB/s eta 0:00:02\n",
            "     -----                                    0.3/2.1 MB 2.1 MB/s eta 0:00:01\n",
            "     ---------                                0.5/2.1 MB 2.8 MB/s eta 0:00:01\n",
            "     -------------                            0.7/2.1 MB 3.0 MB/s eta 0:00:01\n",
            "     -----------------                        0.9/2.1 MB 3.3 MB/s eta 0:00:01\n",
            "     --------------------------               1.4/2.1 MB 4.4 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 2.1/2.1 MB 5.5 MB/s eta 0:00:00\n",
            "Installing collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1\n",
            "    Uninstalling pip-23.1:\n",
            "      Successfully uninstalled pip-23.1\n",
            "Successfully installed pip-23.1.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seaborn is already installed.\n"
          ]
        }
      ],
      "source": [
        "#check if seaborn is installed\n",
        "\n",
        "import subprocess\n",
        "\n",
        "try:\n",
        "    subprocess.check_call(['pip', 'show', 'seaborn'])\n",
        "except subprocess.CalledProcessError:\n",
        "    # Seaborn is not installed\n",
        "    %pip install seaborn\n",
        "else:\n",
        "    print('Seaborn is already installed.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "plotly is already installed.\n"
          ]
        }
      ],
      "source": [
        "#check if plotly is installed\n",
        "\n",
        "import subprocess\n",
        "\n",
        "try:\n",
        "    subprocess.check_call(['pip', 'show', 'plotly'])\n",
        "except subprocess.CalledProcessError:\n",
        "    # plotly is not installed\n",
        "    %pip install plotly\n",
        "else:\n",
        "    print('plotly is already installed.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "xgboost is already installed.\n"
          ]
        }
      ],
      "source": [
        "#check if xgboost is installed\n",
        "\n",
        "import subprocess\n",
        "\n",
        "try:\n",
        "    subprocess.check_call(['pip', 'show', 'xgboost'])\n",
        "except subprocess.CalledProcessError:\n",
        "    # xgboost is not installed\n",
        "    %pip install xgboost\n",
        "else:\n",
        "    print('xgboost is already installed.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tKbBMUSd-rgl"
      },
      "outputs": [],
      "source": [
        "# import necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from sklearn import preprocessing\n",
        "import matplotlib \n",
        "matplotlib.style.use('ggplot')\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# Set display options to show all rows and columns\n",
        "# pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUvDowUwCL-j",
        "outputId": "72070054-98d2-443f-c57e-46a9ff2380d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Sheet names of the given excel file: \n",
            "Üye Listesi\n",
            "Giriş Logları\n",
            "Oyun\n",
            "Konu anlatımı\n",
            "çalışmalar\n",
            "Sınav\n",
            "konu\n"
          ]
        }
      ],
      "source": [
        "# importing openpyxl module\n",
        "import openpyxl\n",
        "\n",
        "# input excel file path\n",
        "inputExcelFile =\"MorpaData.xlsx\"\n",
        "\n",
        "# creating or loading an excel workbook\n",
        "newWorkbook = openpyxl.load_workbook(inputExcelFile)\n",
        "\n",
        "# printing all the sheetnames in an excel file using sheetnames attribute\n",
        "print('The Sheet names of the given excel file: ')\n",
        "\n",
        "# Getting the sheetnames as a list using the sheetnames attribute\n",
        "sheetNames=newWorkbook.sheetnames\n",
        "\n",
        "# Traversing in the sheetNames list\n",
        "for name in sheetNames:\n",
        "   print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKZsCLZ5DtkY",
        "outputId": "a0717b59-17a0-4e8f-cdcb-5e8f796cbfca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       Üye  Şehir    İlçe       Okul  Sınıf\n",
            "0  2070306  10826  162678  120166963      4\n",
            "1  2910824  16378  624995  813905547      6\n",
            "2  3045726  10989  721319  231052437      4\n",
            "3  3661377  10185  376777  733057858      8\n",
            "4  3794510  11631  709268   72006202      4\n",
            "5  3969040  11631  626646  305454095      5\n",
            "6  5084112  11631   23819  659915466      8\n",
            "7  6789503  15012  248394  310622551      3\n",
            "8  7221591  11631  485022  529623633      3\n",
            "9  7899454  14951  599378  265076040      8 \n",
            "\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1999 entries, 0 to 1998\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype\n",
            "---  ------  --------------  -----\n",
            " 0   Üye     1999 non-null   int64\n",
            " 1   Şehir   1999 non-null   int64\n",
            " 2   İlçe    1999 non-null   int64\n",
            " 3   Okul    1999 non-null   int64\n",
            " 4   Sınıf   1999 non-null   int64\n",
            "dtypes: int64(5)\n",
            "memory usage: 78.2 KB\n",
            "None\n",
            "1999\n"
          ]
        }
      ],
      "source": [
        "# get the member data from excel\n",
        "\n",
        "member_df = pd.read_excel('MorpaData.xlsx',sheet_name='Üye Listesi')\n",
        "print(member_df.head(10),'\\n\\n')\n",
        "\n",
        "print(member_df.info())\n",
        "\n",
        "# get the unique number of members\n",
        "\n",
        "print(member_df['Üye'].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "er0hlnd5DwP4",
        "outputId": "63b4ff6e-1344-4d60-8b5d-ee5b7eb18837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   GirişID      Üye            Giriş Zamanı            Çıkış Zamanı  \\\n",
            "0   181915  2070306 2021-09-09 20:54:37.683 2021-09-09 21:46:55.070   \n",
            "1   128004  2910824 2021-09-07 20:33:32.583 2021-09-07 21:25:53.753   \n",
            "2   178974  2910824 2021-09-09 20:18:36.960 2021-09-09 20:58:58.370   \n",
            "3   182887  2910824 2021-09-09 21:10:33.563 2021-09-09 22:04:55.467   \n",
            "4   238434  2910824 2021-09-12 10:59:55.210 2021-09-12 11:04:15.233   \n",
            "5   244552  2910824 2021-09-12 12:32:28.067 2021-09-12 13:28:49.353   \n",
            "6   273273  2910824 2021-09-13 13:25:51.117 2021-09-13 13:58:05.470   \n",
            "7   273943  2910824 2021-09-13 13:58:05.470 2021-09-13 14:36:48.393   \n",
            "8   285795  2910824 2021-09-13 18:44:16.997 2021-09-13 19:44:59.743   \n",
            "9   345946  2910824 2021-09-15 17:06:06.027 2021-09-15 17:51:50.893   \n",
            "\n",
            "   Süre Dakika  \n",
            "0           52  \n",
            "1           52  \n",
            "2           40  \n",
            "3           54  \n",
            "4            5  \n",
            "5           56  \n",
            "6           33  \n",
            "7           38  \n",
            "8           60  \n",
            "9           45   \n",
            "\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21569 entries, 0 to 21568\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype         \n",
            "---  ------        --------------  -----         \n",
            " 0   GirişID       21569 non-null  int64         \n",
            " 1   Üye           21569 non-null  int64         \n",
            " 2   Giriş Zamanı  21569 non-null  datetime64[ns]\n",
            " 3   Çıkış Zamanı  21569 non-null  datetime64[ns]\n",
            " 4   Süre Dakika   21569 non-null  int64         \n",
            "dtypes: datetime64[ns](2), int64(3)\n",
            "memory usage: 842.7 KB\n",
            "None \n",
            "\n",
            "\n",
            "unique member count on login data:  1999\n"
          ]
        }
      ],
      "source": [
        "# get the Login logs data from excel\n",
        "\n",
        "login_df = pd.read_excel('MorpaData.xlsx',sheet_name='Giriş Logları')\n",
        "login_df['Giriş Zamanı'] = pd.to_datetime(login_df['Giriş Zamanı'], format='%d/%m/%Y %H:%M:%S')\n",
        "login_df['Çıkış Zamanı'] = pd.to_datetime(login_df['Çıkış Zamanı'], format='%d/%m/%Y %H:%M:%S')\n",
        "print(login_df.head(10),'\\n\\n')\n",
        "\n",
        "print(login_df.info(),'\\n\\n')\n",
        "\n",
        "\n",
        "# get the unique number of members on login data\n",
        "print(\"unique member count on login data: \",login_df['Üye'].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lf3miMv5D6md",
        "outputId": "31746262-361e-44b5-fa40-7e2994d56103"
      },
      "outputs": [],
      "source": [
        "# get the lecturing logs data from excel\n",
        "\n",
        "lecturing_df = pd.read_excel('MorpaData.xlsx',sheet_name='Konu anlatımı')\n",
        "lecturing_df['Giriş Zamanı'] = pd.to_datetime(lecturing_df['Giriş Zamanı'], format='%d/%m/%Y %H:%M:%S')\n",
        "lecturing_df['Çıkış Zamanı'] = pd.to_datetime(lecturing_df['Çıkış Zamanı'], format='%d/%m/%Y %H:%M:%S')\n",
        "\n",
        "# calculate the duration of the lecturing\n",
        "\n",
        "lecturing_df['lec_Süre'] = (lecturing_df['Çıkış Zamanı'] - lecturing_df['Giriş Zamanı']).dt.total_seconds().astype(int)\n",
        "\n",
        "print(lecturing_df.head(10),'\\n\\n')\n",
        "\n",
        "print(lecturing_df.info(),'\\n\\n')\n",
        "\n",
        "\n",
        "# get the unique number of members on lecturing data\n",
        "print(\"Unique number of users on lecturing: \", lecturing_df['Üye'].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO-RVuCTD-nn",
        "outputId": "a38cf49d-61ed-417e-93e5-d3eb44dfcbaa"
      },
      "outputs": [],
      "source": [
        "# get the member studies data from excel\n",
        "\n",
        "studies_df = pd.read_excel('MorpaData.xlsx',sheet_name='çalışmalar')\n",
        "studies_df['Giriş Zamanı'] = pd.to_datetime(studies_df['Giriş Zamanı'], format='%d/%m/%Y %H:%M:%S')\n",
        "studies_df['Çıkış Zamanı'] = pd.to_datetime(studies_df['Çıkış Zamanı'], format='%d/%m/%Y %H:%M:%S')\n",
        "\n",
        "studies_df['stud_Süre'] = (studies_df['Çıkış Zamanı'] - studies_df['Giriş Zamanı']).dt.total_seconds().astype(int)\n",
        "\n",
        "print(studies_df.head(10),'\\n\\n')\n",
        "\n",
        "print(studies_df.info(),'\\n\\n')\n",
        "\n",
        "# get the unique number of members on studies data\n",
        "print(\"unique member count on studies data: \",studies_df['Üye'].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QGYXqBHEIDR",
        "outputId": "eba89494-d351-4c8d-a0d5-d0967583d3c0"
      },
      "outputs": [],
      "source": [
        "# get the member exams data from excel\n",
        "\n",
        "exams_df = pd.read_excel('MorpaData.xlsx',sheet_name='Sınav')\n",
        "exams_df['Giriş Zamanı'] = exams_df['Giriş Zamanı'].apply(lambda x: x.strftime(\"%d/%m/%Y  %H:%M:%S\"))\n",
        "exams_df['Çıkış Zamanı'] = exams_df['Çıkış Zamanı'].apply(lambda x: x.strftime(\"%d/%m/%Y  %H:%M:%S\"))\n",
        "\n",
        "exams_df['Giriş Zamanı'] = pd.to_datetime(exams_df['Giriş Zamanı'], format='%d/%m/%Y %H:%M:%S')\n",
        "exams_df['Çıkış Zamanı'] = pd.to_datetime(exams_df['Çıkış Zamanı'], format='%d/%m/%Y %H:%M:%S')\n",
        "\n",
        "exams_df['Giriş Zamanı']\n",
        "\n",
        "print(exams_df.head(10),'\\n\\n')\n",
        "\n",
        "print(exams_df.info(),'\\n\\n')\n",
        "\n",
        "# get the unique number of members on exams data\n",
        "print(\"unique member count on exams data: \",exams_df['Üye'].nunique())\n",
        "\n",
        "\n",
        "# wrong answers are not deducted from the total score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "uqgM7MckE2T4",
        "outputId": "0b8a4f24-5e55-4d29-beba-dd70ca49b2a3"
      },
      "outputs": [],
      "source": [
        "# get the member subject data from excel\n",
        "\n",
        "subject_df = pd.read_excel('MorpaData.xlsx',sheet_name='konu')\n",
        "subject_df.head(10)\n",
        "\n",
        "#sort according to aktif materyal sayısı\n",
        "\n",
        "subject_df.sort_values(by=['Aktif Materyal Sayısı'],ascending=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "iw9InXsHF6i8",
        "outputId": "4a233ab5-6ce8-486c-f5a6-b4b2fa956489"
      },
      "outputs": [],
      "source": [
        "#left join the exam and subject dataframes\n",
        "\n",
        "exam_subject_df = pd.merge(exams_df,subject_df,how='left',left_on='Konu',right_on='Konu')\n",
        "\n",
        "# change column names for further join operations\n",
        "exam_subject_df.rename(\n",
        "    columns={\"Giriş Zamanı\": \"S_Giriş Zamanı\", \"Çıkış Zamanı\": \"S_Çıkış Zamanı\", \"Süre\":\"S_süre\"},\n",
        "    inplace=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# drop non-numeric sınıf rows\n",
        "\n",
        "exam_subject_df = exam_subject_df[exam_subject_df['Sınıf'].notna()]\n",
        "\n",
        "exam_subject_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "exam_subject_df['Sınıf'] = exam_subject_df['Sınıf'].astype('int64')\n",
        "exam_subject_df['Ders'] = exam_subject_df['Ders'].astype('int64')\n",
        "exam_subject_df['Aktif Materyal Sayısı'] = exam_subject_df['Aktif Materyal Sayısı'].astype('int64')\n",
        "exam_subject_df['Toplam Materyal Sayısı'] = exam_subject_df['Toplam Materyal Sayısı'].astype('int64')\n",
        "\n",
        "exam_subject_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-yZKkBTdRVb"
      },
      "outputs": [],
      "source": [
        "# add cumulative lecture time to exam_subject dataframe for each member according to the subject prior to exam date s_Giriş Zamanı\n",
        "\n",
        "# calculate cumulative lecture time before the exam date for each member of each subject\n",
        "exam_subject_df['cum_lecture_time'] = 0\n",
        "for index, row in exam_subject_df.iterrows():\n",
        "    df = lecturing_df[lecturing_df['Üye'] == row['Üye']]\n",
        "    df = df[df['Konu'] == row['Konu']]\n",
        "    df = df[df['Giriş Zamanı'] < row['S_Giriş Zamanı']]\n",
        "    df['lec_Süre'] = df['lec_Süre'].astype('int64')\n",
        "    exam_subject_df.at[index,'cum_lecture_time'] = df['lec_Süre'].sum()\n",
        "\n",
        "# calculate cumulative study time before the exam date for each member of each subject\n",
        "exam_subject_df['cum_study_time'] = 0\n",
        "for index, row in exam_subject_df.iterrows():\n",
        "    df = studies_df[studies_df['Üye'] == row['Üye']]\n",
        "    df = df[df['Konu'] == row['Konu']]\n",
        "    df = df[df['Giriş Zamanı'] < row['S_Giriş Zamanı']]\n",
        "    df['stud_Süre'] = df['stud_Süre'].astype('int64')\n",
        "    exam_subject_df.at[index,'cum_study_time'] = df['stud_Süre'].sum()\n",
        "\n",
        "exam_subject_df['total_study_time'] = exam_subject_df['cum_lecture_time'] + exam_subject_df['cum_study_time']\n",
        "        \n",
        "exam_subject_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TJnVX2PMr3z",
        "outputId": "6cf92ae3-861c-44d0-87e5-149fb6566244"
      },
      "outputs": [],
      "source": [
        "# to tag the members who attempt gaming the system, I crate a deep copy of exams_df to exams_df_gtsLabeled.\n",
        "\n",
        "exams_df_gtsLabeled = exam_subject_df.copy(deep=True)\n",
        "\n",
        "# create a new column for labeling and overlapping time\n",
        "\n",
        "exams_df_gtsLabeled['Label'] = \"\"\n",
        "exams_df_gtsLabeled['Overlap (secs.)'] = \"\"\n",
        "\n",
        "# update the index of exams_df_gtsLabeled\n",
        "\n",
        "exams_df_gtsLabeled.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# then we write the conditions for labeling the data who \"Gaming the System\". 1 for gaming, 0 for not gaming.\n",
        "\n",
        "for i in range(1,len(exams_df_gtsLabeled)):\n",
        "    if exams_df_gtsLabeled['Üye'][i-1] == exams_df_gtsLabeled['Üye'][i]:\n",
        "        if exams_df_gtsLabeled['Sınav'][i-1] == exams_df_gtsLabeled['Sınav'][i]:\n",
        "            if exams_df_gtsLabeled['Konu'][i-1] == exams_df_gtsLabeled['Konu'][i]:\n",
        "                if (exams_df_gtsLabeled['S_Çıkış Zamanı'][i-1] > exams_df_gtsLabeled['S_Giriş Zamanı'][i]) and (exams_df_gtsLabeled['Puan'][i-1] < exams_df_gtsLabeled['Puan'][i]) and (exams_df_gtsLabeled['GirişLog'][i-1] == exams_df_gtsLabeled['GirişLog'][i]):\n",
        "                    exams_df_gtsLabeled['Label'][i] = 1\n",
        "                    exams_df_gtsLabeled['Overlap (secs.)'][i] = (exams_df_gtsLabeled['S_Giriş Zamanı'][i] - exams_df_gtsLabeled['S_Çıkış Zamanı'][i-1]).total_seconds() * -1  # this is the overlapping time in seconds \n",
        "\n",
        "exams_df_gtsLabeled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Ce-tzZEyQ2g4",
        "outputId": "bc3e0546-414c-471d-96e7-2d000c3be6cb"
      },
      "outputs": [],
      "source": [
        "#Sort the tagged data according to the member and subject\n",
        "\n",
        "exams_df_gtsLabeled.sort_values(by=['Konu','Üye'])\n",
        "\n",
        "# name the table as df for the sake of simplicity\n",
        "\n",
        "df = exams_df_gtsLabeled\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Label'].value_counts()\n",
        "\n",
        "# we have 7878 rows data and 290 of them are labeled as 1. This means that 290 members attempted gaming the system.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the gaming the system data\n",
        "\n",
        "df.loc[df['Label'] == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fill with zero if Label column is not 1\n",
        "\n",
        "df.replace(\"\", 0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check the label value counts\n",
        "\n",
        "df['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "value_counts = df['Label'].value_counts()\n",
        "value_counts.plot(kind=\"bar\", title=\"Class distribution of the target(Label) variable\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWgyZphpREp4"
      },
      "source": [
        "# ML SIDE"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#describe the latest df \n",
        "\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#change object type to related datatype. Label and Overlap(secs.) are going to be int64\n",
        "\n",
        "df['Overlap (secs.)'] = df['Overlap (secs.)'].astype('int64')\n",
        "\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# change the datetime type to unix time\n",
        "\n",
        "df['S_Giriş Zamanı'] = df['S_Giriş Zamanı'].astype('int64') // 10**9\n",
        "df['S_Çıkış Zamanı'] = df['S_Çıkış Zamanı'].astype('int64') // 10**9\n",
        "\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.options.display.float_format = '{:.0f}'.format\n",
        "\n",
        "df.describe().T  # T is for transpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Shows the Distribution of GTS with respect to Class\n",
        "\n",
        "# Subset your data to only include Label=1\n",
        "df_label_1 = df[df[\"Label\"] == 1]\n",
        "\n",
        "sns.countplot(x=\"Sınıf\", hue=\"Label\", data=df_label_1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute the correlation matrix\n",
        "corr = df.corr()\n",
        "\n",
        "# Generate a heatmap plot of the correlation matrix using Seaborn\n",
        "sns.heatmap(corr, cmap=\"YlGnBu\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# we need to drop the columns that are highly correlated with each other to avoid multicollinearity\n",
        "\n",
        "df.drop([\"Doğru Sayısı\",\"Yanlış Sayısı\",\"Boş Sayısı\",\"cum_lecture_time\",\"cum_study_time\",\"Overlap (secs.)\"], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute the correlation matrix\n",
        "corr = df.corr()\n",
        "\n",
        "# Generate a heatmap plot of the correlation matrix using Seaborn\n",
        "sns.heatmap(corr, cmap=\"YlGnBu\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to remove the columns which has single value, we investigate the unique values of each column\n",
        "\n",
        "print(df['Sınav Türü'].unique())\n",
        "print(df['Sınıf'].unique())\n",
        "print(df['Label'].unique())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "we have different values on the columns so no need any extraction for unique values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have no null values so no need to deal with missing data. Since we are planning to use xgboost, we need only int, float and bool values. Our data is already in this format so no need to convert any data type. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Format the data 1 - Split data into train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# since we try to predict the Label column, we need to drop this column before assigning the data to X\n",
        "\n",
        "X = df.drop('Label', axis=1).copy()\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# y is the Label column which we want to predict\n",
        "\n",
        "y = df['Label'].copy()\n",
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Format the data 2 : One Hot Encoding \n",
        "\n",
        "# One Hot Encoding is not good for logistic regression but great for tree based models for categorical variables\n",
        "\n",
        "X_encoded = pd.get_dummies(X, columns=['Üye', 'Sınav','Konu','Sınav Türü','GirişLog','Sınıf','Ders','Aktif Materyal Sayısı', 'Toplam Materyal Sayısı'])\n",
        "\n",
        "print(X_encoded.info())\n",
        "\n",
        "X_encoded.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# verify that y has only 0 and 1 values\n",
        "\n",
        "y.unique()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build a preliminary XGBoost Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check the target data imbalance\n",
        "\n",
        "sum(y)/len(y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our target variable is highly imbalanced. Thus, we use stratified sampling to split the data into train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# split the data into train and test sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, random_state=42, test_size=0.2, stratify=y)   #test_size=0.2 could be added to split in %80 train and %20 test "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install -U imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from imblearn.over_sampling import SMOTE\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# numerical_cols = ['S_Giriş Zamanı', 'S_Çıkış Zamanı', 'Puan', 'S_süre', 'total_study_time']\n",
        "\n",
        "# # apply standardization to numerical features\n",
        "# scaler = StandardScaler()\n",
        "# X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
        "# X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # apply SMOTE to balance target variable\n",
        "# smote = SMOTE(random_state=42)\n",
        "# X_train, y_train = smote.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check if stratification is done correctly\n",
        "\n",
        "print('y_train ratio:', sum(y_train)/len(y_train))\n",
        "print('y_test ratio:',sum(y_test)/len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(y_test)/(len(y_test)+len(y_train))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It seems stratified sampling is working well. \n",
        "\n",
        "\n",
        "Now we use XGB Classifier and Instead of determinin the optimal number of trees, we use early stopping to determine the optimal number of trees. Early Stopping is a method that allows you to specify a performance metric to evaluate your model on every step of the training process, and stop the training process when the performance metric no longer improves for a given number of steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create XGBClassifier model\n",
        "\n",
        "clf_xgb = xgb.XGBClassifier(objective='binary:logistic', tree_method='gpu_hist', seed=42)\n",
        "clf_xgb.fit(X_train, y_train, verbose=True, early_stopping_rounds=10, eval_metric='auc', eval_set=[(X_test, y_test)]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay.from_estimator(clf_xgb, X_test, y_test, cmap='Blues', values_format='d' ,display_labels=['Not GTS', 'GTS'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our default XGBoost model is not performing well. We need to tune the hyperparameters to improve the performance.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimize the hyperparameters using cross validation and GridSearchCV"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- max_depth: This hyperparameter controls the maximum depth of a tree in the model. Higher values can result in overfitting, so it's important to choose an appropriate value that balances model complexity with generalization.\n",
        "\n",
        "- learning_rate: This hyperparameter controls the step size of each update during training. Lower values result in slower training but can improve the accuracy of the final model. Higher values can speed up training but may lead to less accurate models.\n",
        "\n",
        "- gamma: This hyperparameter controls the minimum reduction in loss required to split a node during tree construction. Higher values make the model more conservative, while lower values can result in overfitting.\n",
        "\n",
        "- reg_alpha: This hyperparameter controls the L1 regularization penalty on the weights of the model. Higher values result in sparser models that may be less prone to overfitting.\n",
        "\n",
        "- reg_lambda: This hyperparameter controls the L2 regularization penalty on the weights of the model. Higher values result in smoother models that may be less prone to overfitting.\n",
        "\n",
        "- subsample: This hyperparameter controls the fraction of the training data that is used for each boosting iteration. Lower values can improve generalization by reducing the impact of individual observations, while higher values can improve accuracy by increasing the diversity of the model.\n",
        "\n",
        "- colsample_bytree: This hyperparameter controls the fraction of features that are used for each tree in the model. Lower values can reduce the impact of noisy features and improve generalization, while higher values can improve accuracy by capturing more information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# first try\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [6, 9],\n",
        "    'learning_rate': [0.001, 0.005, 0.01],\n",
        "    #'n_estimators': [100, 200],\n",
        "    'gamma': [0.0, 0.25],\n",
        "    'subsample': [0.5, 0.9],\n",
        "    'colsample_bytree': [0.5, 0.9],\n",
        "    'reg_alpha': [0],\n",
        "    'reg_lambda': [10],\n",
        "    'scale_pos_weight': [30, 60]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import get_scorer_names\n",
        "\n",
        "get_scorer_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# since the operation takes too long, we commented out the code\n",
        "\n",
        "\n",
        "# optimal_params = GridSearchCV(\n",
        "#     estimator=clf_xgb,\n",
        "#     param_grid=param_grid,\n",
        "#     scoring='roc_auc',\n",
        "#     verbose=4,\n",
        "#     cv=5\n",
        "# )\n",
        "\n",
        "\n",
        "# optimal_params.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# optimal_params.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# optimal_params.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# optimal_params.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# resultsdf = pd.DataFrame(optimal_params.cv_results_)\n",
        "# resultsdf = resultsdf.sort_values(by=['rank_test_score'], ascending=False)\n",
        "# resultsdf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# we use xgboost model with optimized parameters.\n",
        "\n",
        "clf_xgb = xgb.XGBClassifier(seed=42,\n",
        "                            objective='binary:logistic',\n",
        "                            gamma=0.25,\n",
        "                            learning_rate=0.01,\n",
        "                            max_depth=6,                            \n",
        "                            reg_alpha=0.25,\n",
        "                            reg_lambda=5,\n",
        "                            scale_pos_weight=30,\n",
        "                            subsample=0.9,\n",
        "                            colsample_bytree=0.5,\n",
        "                            n_estimators=100,\n",
        "                            )\n",
        "\n",
        "clf_xgb.fit(X_train, \n",
        "            y_train, \n",
        "            verbose=True, \n",
        "            early_stopping_rounds=10, \n",
        "            eval_metric='aucpr', \n",
        "            eval_set=[(X_test, y_test)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay.from_estimator(clf_xgb, X_test, y_test, cmap='Blues', values_format='d' ,display_labels=['Not GTS', 'GTS'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# buraya tree çizdir.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "3e4e368f4678aeea63aa88b109cf85079962017e54a5bcf2a7b2b7c89b67607e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
